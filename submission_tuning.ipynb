{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de5375f1-069d-47d1-bcc9-1f8e00f9939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "folder_path = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa8ef870-801b-40a1-97a3-0aa7bfe4ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_and_truth(data_list, truth_list, cols=['Chr', 'START_POS_REF', 'END_POS_REF'], split=False, use_small=True):\n",
    "    \n",
    "    df_res = []\n",
    "    truth_res = {}\n",
    "\n",
    "    extra = \"\" if use_small else \"-all\"\n",
    "    for data_name, truth_name in zip(data_list, truth_list):\n",
    "        data_path = folder_path + f\"snv-parse-{data_name}{extra}.txt\"\n",
    "        df = pd.read_csv(data_path, sep='\\t', low_memory=False)\n",
    "        df['is_real'] = data_name[:4] == 'real'\n",
    "        df['ds_name'] = data_name\n",
    "        df['ds_type'] = data_name[:5]\n",
    "        truth_path = folder_path + f\"{data_name}/{truth_name}.bed\"\n",
    "        truth = pd.read_csv(truth_path, sep='\\t', header=None, names = ['Chr', 'START_POS_REF', 'END_POS_REF'])\n",
    "        truth['label'] = 1\n",
    "        df_res.append(df)\n",
    "        truth_res[data_name] = truth\n",
    "    \n",
    "    return df_res, truth_res\n",
    "\n",
    "def get_df(data_name):\n",
    "    \n",
    "    data_path = folder_path + f\"snv-parse-{data_name}.txt\"\n",
    "    df = pd.read_csv(data_path, sep='\\t', low_memory=False)\n",
    "    df['is_real'] = data_name[:4] == 'real'\n",
    "    df['ds_name'] = data_name\n",
    "    df['ds_type'] = data_name[:5]\n",
    "    df['label'] = -1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83f1e3b8-774c-4197-b5aa-6f50f8a947b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = [\"real1\", \"real2_part1\", \"syn1\", \"syn2\", \"syn3\", \"syn4\", \"syn5\"]\n",
    "#data_list = [\"real1\", \"real2_part1\"]\n",
    "truth_list = [\"real1_truth\", \"real2_truth_chr1to5\", \"syn1_truth\", \"syn2_truth\", \"syn3_truth\", \"syn4_truth\", \"syn5_truth\" ]\n",
    "#truth_list = [\"real1_truth\", \"real2_truth_chr1to5\"]\n",
    "df_list, truth_dict = get_df_and_truth(data_list, truth_list, use_small=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66e69c95-40eb-456a-9223-16ca88348c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chr                      73\n",
       "START_POS_REF         49294\n",
       "END_POS_REF           49294\n",
       "REF                       4\n",
       "ALT                       4\n",
       "REF_MFVdVs               60\n",
       "ALT_MFVdVs              590\n",
       "Sample_Name               1\n",
       "FILTER_Mutect2            2\n",
       "FILTER_Freebayes          2\n",
       "FILTER_Vardict            2\n",
       "FILTER_Varscan            2\n",
       "m2_ClippingRankSum        5\n",
       "m2_DP                   923\n",
       "m2_ECNT                  34\n",
       "m2_FS                  4856\n",
       "m2_MQ                  2086\n",
       "m2_MQ0                  354\n",
       "m2_MQRankSum           3763\n",
       "m2_ReadPosRankSum      4408\n",
       "f_AN                      4\n",
       "f_DP                    594\n",
       "f_DPB                   594\n",
       "f_EPPR                 2110\n",
       "f_GTI                     4\n",
       "f_MQMR                 4412\n",
       "f_NS                      2\n",
       "f_NUMALT                  3\n",
       "f_ODDS                 6402\n",
       "f_PAIREDR              1313\n",
       "f_PQR                     2\n",
       "f_PRO                     2\n",
       "f_QR                   3745\n",
       "f_RO                    526\n",
       "f_RPPR                 2273\n",
       "f_SRF                   331\n",
       "f_SRP                  2506\n",
       "f_SRR                   337\n",
       "vs_DP                  2172\n",
       "vs_GPV                 2084\n",
       "vs_SPV                20521\n",
       "vs_SS                     4\n",
       "vs_SSC                  206\n",
       "vd_DP                   389\n",
       "vd_MSI                   52\n",
       "vd_MSILEN                10\n",
       "vd_SHIFT3                50\n",
       "vd_SOR                 5935\n",
       "vd_SSF                 6683\n",
       "vd_VD                   143\n",
       "is_real                   1\n",
       "ds_name                   1\n",
       "ds_type                   1\n",
       "label                     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_list = [df.merge(truth, how='left').fillna({'label':0}) for df, truth in zip(df_list, truth_dict.values())] + [get_df(\"real2_part2\")]\n",
    "merged_list = [df.drop(labels=['vd_SAMPLE', 'vd_STATUS', 'vd_TYPE'], axis=1) for df in merged_list]\n",
    "merged_list[0].apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d876cbc-d641-447e-84b8-c87905251c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_inf_values(df, inf_list=[\"vd_SOR\"]):\n",
    "    # for col in inf_list:\n",
    "    #    df.loc[df.loc[:,col] == float('inf'), col] = -1\n",
    "    df = df.drop(labels=inf_list, axis=1)\n",
    "    return df\n",
    "\n",
    "def handle_filters(df, columns):\n",
    "    res_df = [df]\n",
    "    res_cols = []\n",
    "\n",
    "    for col in columns:\n",
    "        cat_filter_df = pd.get_dummies(df.loc[:,col].str.split(';').explode()).groupby(level=0).sum()\n",
    "        cat_filter_df = cat_filter_df.rename(lambda x: f'{col}_{x}', axis=1)\n",
    "        res_df.append(cat_filter_df)\n",
    "        res_cols += list(cat_filter_df.columns)\n",
    "\n",
    "    return pd.concat(res_df, axis=1), res_cols\n",
    "    \n",
    "def handle_nan_values(d_list, sample_list, imputer):\n",
    "    \n",
    "    df = pd.concat(d_list, axis=0).reset_index(drop=True)\n",
    "\n",
    "    #filter_list = [\"FILTER_Mutect2\", \"FILTER_Freebayes\",\"FILTER_Vardict\",\"FILTER_Varscan\"]\n",
    "    #df, filter_cols = handle_filters(df, filter_list[1:])\n",
    "    df = handle_inf_values(df)\n",
    "    \n",
    "    #nan_cols = list(set(df.columns[df.isna().any()]) - set(filter_list))\n",
    "    nan_cols = list(set(df.columns[df.isna().any()]))\n",
    "    new_nan_cols = [x + \"_nan_ind\" for x in nan_cols]\n",
    "    df[new_nan_cols] = df.loc[:,nan_cols].isna()\n",
    "    \n",
    "    df.loc[df['ds_name'].isin(sample_list),nan_cols] = imputer.fit_transform(df.loc[df['ds_name'].isin(sample_list),nan_cols])\n",
    "    if not df['ds_name'].isin(sample_list).all():\n",
    "        df.loc[~df['ds_name'].isin(sample_list),nan_cols] = imputer.transform(df.loc[~df['ds_name'].isin(sample_list),nan_cols])\n",
    "        \n",
    "    return df, nan_cols, new_nan_cols\n",
    "    \n",
    "def create_more_cat_values(df, columns):\n",
    "    \n",
    "    ret_cols = []\n",
    "    for c in columns:\n",
    "        s = df[c].str.split('/').apply(lambda x: x[:-1])\n",
    "        new_cols = [c + f\"_{i}\" for i in range(len(s.iloc[0]))]\n",
    "        df[new_cols] = pd.DataFrame(np.vstack(s.values))\n",
    "        ret_cols += new_cols\n",
    "\n",
    "        for col in new_cols:\n",
    "            rare_cols = df.loc[:,col].value_counts()[(df.loc[:,col].value_counts() <= 200)].index\n",
    "            df.loc[df.loc[:,col].isin(rare_cols),col] = 'rare'\n",
    "            \n",
    "    return df, ret_cols\n",
    "        \n",
    "def handle_cat_values(df, cat_list):\n",
    "    cat_df = pd.get_dummies(df, columns=cat_list, drop_first=True)\n",
    "    cat_cols = list(set(cat_df.columns) - set(df.columns))\n",
    "    cat_df['Chr'] = df['Chr']\n",
    "    return cat_df, cat_cols\n",
    "\n",
    "def get_X_y(df, sample_list, feature_list):\n",
    "    df = df[df['ds_name'].isin(sample_list)]\n",
    "    X = df.loc[:,feature_list].astype(float)\n",
    "    y = df.loc[:,\"label\"].astype(float)\n",
    "    return X, y\n",
    "\n",
    "def preprocess_data(train_sample_list):\n",
    "    col_list = [\"is_real\"]\n",
    "\n",
    "    # Handling nan values\n",
    "    #imputer=SimpleImputer(strategy='constant', fill_value=0)\n",
    "    imputer=SimpleImputer(strategy='median')\n",
    "    #imputer=KNNImputer(n_neighbors=10)\n",
    "    df, nan_cols, new_nan_cols = handle_nan_values(merged_list, train_sample_list, imputer)\n",
    "    \n",
    "    # Handling Categorical Data\n",
    "    ret_cols = []\n",
    "    add_cols = [\"REF_MFVdVs\", \"ALT_MFVdVs\"]\n",
    "    df, ret_cols = create_more_cat_values(df, add_cols)\n",
    "    \n",
    "    cat_cols = []#, \"ALT\"]\n",
    "    cat_list = ['ds_type', \"REF\", \"ALT\"] + ret_cols\n",
    "    df, cat_cols = handle_cat_values(df, cat_list)\n",
    "    \n",
    "    # Combining all features and getting training data\n",
    "    feature_list = col_list + nan_cols + new_nan_cols + cat_cols\n",
    "    return df, feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e1a6e84-f49b-4d16-831d-7094eb87ecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_list = ['real1']\n",
    "df, feature_list = preprocess_data(train_sample_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ad515e0-0004-4e24-975a-de06cdf3faa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "def calc_F1(pred, truth):\n",
    "    predv = pred['Chr'].astype(str) + pred['START_POS_REF'].astype(str)\n",
    "    truthv = truth['Chr'].astype(str) + truth['START_POS_REF'].astype(str)\n",
    "\n",
    "    res = pd.DataFrame(columns=['TP', 'FP', 'FN', 'Precision', 'Recall', 'F1'])\n",
    "\n",
    "    res.loc[0, 'TP'] = sum(predv.isin(truthv))\n",
    "    res.loc[0, 'FP'] = sum(~predv.isin(truthv))\n",
    "    res.loc[0, 'FN'] = sum(~truthv.isin(predv))\n",
    "\n",
    "    res.loc[0, 'Precision'] = res.loc[0, 'TP'] / (res.loc[0, 'TP'] + res.loc[0, 'FP'])\n",
    "    res.loc[0, 'Recall'] = res.loc[0, 'TP'] / (res.loc[0, 'TP'] + res.loc[0, 'FN'])\n",
    "    res.loc[0, 'F1'] = (2 * res.loc[0, 'Precision'] * res.loc[0, 'Recall']) / (res.loc[0, 'Precision'] + res.loc[0, 'Recall'])\n",
    "\n",
    "    return res\n",
    "\n",
    "def get_class_weights(y):    \n",
    "    classes = np.unique(y)\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=classes, y=y)\n",
    "    class_weights = dict(zip(classes, weights))\n",
    "    return class_weights\n",
    "\n",
    "def get_pred(train_ds_name, test_ds_name, model_class, model_params, threshold=0.5, syn_sample_weight=0.001):\n",
    "    X_train, y_train = get_X_y(df, train_ds_name, feature_list)\n",
    "\n",
    "    #class_weight = get_class_weights(y_train.loc[X_train['is_real'].astype(bool)])\n",
    "    class_weight = get_class_weights(y_train.loc[X_train['is_real'].astype(bool)])\n",
    "    model = model_class.set_params(**model_params, class_weight=class_weight)\n",
    "    sample_weight = X_train['is_real'] + syn_sample_weight * (1 - X_train['is_real'])\n",
    "    model.fit(X_train, y_train, sample_weight)\n",
    "    \n",
    "    X_test, y_test = get_X_y(df, [test_ds_name], feature_list)\n",
    "    pred_proba = model.predict_proba(X_test)\n",
    "    y_pred = (pred_proba[:,1] >= threshold)  \n",
    "\n",
    "    return y_pred\n",
    "    \n",
    "def run_test(train_ds_name, test_ds_name, model_class, model_params, threshold=0.5, syn_sample_weight=0.001):\n",
    "\n",
    "    y_pred = get_pred(train_ds_name, test_ds_name, model_class, model_params, threshold, syn_sample_weight)\n",
    "    pred = df[df[\"ds_name\"]==test_ds_name].loc[y_pred.astype(bool),['Chr', 'START_POS_REF', 'END_POS_REF']]\n",
    "    res = calc_F1(pred, truth_dict[test_ds_name])\n",
    "    \n",
    "    return res\n",
    "\n",
    "def save_pred(train_ds_name, test_ds_name_list, model, model_params, threshold=0.5, syn_sample_weight=0.001):\n",
    "\n",
    "    Path(\"./predictions\").mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    X_train, y_train = get_X_y(df, train_ds_name, feature_list)\n",
    "    class_weight='balanced_subsample'\n",
    "    #class_weight = get_class_weights(y_train.loc[X_train['is_real'].astype(bool)])\n",
    "    sample_weight = X_train['is_real'] + syn_sample_weight * (1 - X_train['is_real'])\n",
    "    model = model.set_params(**model_params, class_weight=class_weight)\n",
    "    model.fit(X_train, y_train, sample_weight=sample_weight)\n",
    "\n",
    "    res = []\n",
    "    for test_ds_name in test_ds_name_list:\n",
    "        X_test, y_test = get_X_y(df, [test_ds_name], feature_list)\n",
    "        y_pred = model.predict(X_test)\n",
    "        pred = df[df[\"ds_name\"]==test_ds_name].loc[y_pred.astype(bool),['Chr', 'START_POS_REF', 'END_POS_REF']]\n",
    "        pred.to_csv(f'./predictions/my-{test_ds_name}-predictions.bed', index=False, sep='\\t', header=False)\n",
    "    \n",
    "        if test_ds_name in truth_dict:\n",
    "            score = calc_F1(pred, truth_dict[test_ds_name])\n",
    "            score['ds_name'] = test_ds_name\n",
    "            res.append(score)\n",
    "    \n",
    "    return pd.concat(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fccab674-560b-43e6-a7c7-4c6aa6ae1c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "396d7dd5-c562-4e08-a6d6-0303e9b23d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, ExtraTreesClassifier, StackingClassifier, VotingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42, max_depth=25, verbose=2)\n",
    "gb = HistGradientBoostingClassifier()\n",
    "lgbm = LGBMClassifier(n_estimators=1000, learning_rate=0.05,verbose=2, n_jobs=-1, random_state=42)\n",
    "lgr = LogisticRegression(C=1000)\n",
    "extra = ExtraTreesClassifier(n_estimators=1000, n_jobs=-1, random_state=42, verbose=2)\n",
    "extra_params = {\"n_estimators\" : 1000, \"min_samples_split\" : 10, \"max_depth\" : 48, \"verbose\" : 1, \"n_jobs\" : -1, \"random_state\" : 42}\n",
    "catboost = CatBoostClassifier()\n",
    "catboost_params = {\"num_trees\" : 1000, \"learning_rate\" : 0.09, \"depth\" : 5, \"task_type\" : \"GPU\"}\n",
    "xgb = XGBClassifier()\n",
    "xgb_params = {\"n_estimators\" : 1000, \"learning_rate\": 0.1, \"random_state\" : 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "666c66e5-3cde-404b-a915-619e97802983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "rf = RandomForestClassifier()\n",
    "rf_params = {\"n_estimators\" : 100, \"min_samples_split\" : 2, \"max_depth\" : 64, \"oob_score\" : False, \"min_samples_leaf\" : 1, \"bootstrap\" : True, \"verbose\" : 1, \"n_jobs\" : -1, \"random_state\" : 42}\n",
    "\n",
    "#model, model_params = extra, extra_params\n",
    "model, model_params = rf, rf_params\n",
    "#model, model_params = copy(catboost), copy(catboost_params)\n",
    "#model, model_params = xgb, xgb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "838b835e-58e1-4ef4-b5a2-8169ad8fe5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    7.4s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9826455842653298, 0.8554913294797687)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = save_pred(['real1', 'syn1', 'syn2', 'syn3', 'syn4', 'syn5'], [\"real1\", \"real2_part1\"], model, model_params, syn_sample_weight=0.1)\n",
    "results.iloc[0]['F1'], results.iloc[1]['F1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "554f91b8-0a87-4f47-b3ad-b2936c44a807",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    6.7s finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "model, model_params = rf, rf_params\n",
    "rf_results = save_pred(['real1', 'syn1', 'syn2', 'syn3', 'syn4', 'syn5'], [\"real2_part1\"], model, model_params, syn_sample_weight=0.1)\n",
    "model, model_params = xgb, xgb_params\n",
    "#xgb_results = save_pred(['real1', 'syn1', 'syn2', 'syn3', 'syn4', 'syn5'], [\"real2_part1\"], model, model_params, syn_sample_weight=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "38347814-950d-4383-849e-461e9b80f0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>real2_part1</th>\n",
       "      <td>370</td>\n",
       "      <td>4</td>\n",
       "      <td>121</td>\n",
       "      <td>0.989305</td>\n",
       "      <td>0.753564</td>\n",
       "      <td>0.855491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TP FP   FN Precision    Recall        F1\n",
       "ds_name                                               \n",
       "real2_part1  370  4  121  0.989305  0.753564  0.855491"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.set_index('ds_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463ceb3c-7f13-4de7-a3e7-8be0f749904c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8be7990-4a8d-4a53-bed2-d14cda1c745f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
